{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Step 1: Load the dataset\n",
        "df_filtered = pd.read_json('/content/train.json')\n",
        "df_filtered = df_filtered.sample(frac=0.1, random_state=42)\n",
        "\n",
        "# Step 2: Convert 'created' column to datetime format\n",
        "df_filtered['created'] = pd.to_datetime(df_filtered['created'])\n",
        "\n",
        "# Step 3: Extract useful components from the 'created' column\n",
        "df_filtered['year'] = df_filtered['created'].dt.year\n",
        "df_filtered['month'] = df_filtered['created'].dt.month\n",
        "df_filtered['day'] = df_filtered['created'].dt.day\n",
        "df_filtered['hour'] = df_filtered['created'].dt.hour\n",
        "df_filtered['minute'] = df_filtered['created'].dt.minute\n",
        "df_filtered['second'] = df_filtered['created'].dt.second\n",
        "\n",
        "# Drop the original 'created' column as it's no longer needed\n",
        "df_filtered.drop(columns=['created'], inplace=True)\n",
        "df_filtered.drop(columns=['manager_id'], inplace=True)"
      ],
      "metadata": {
        "id": "KAgRSCl67NYL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Process list columns ('features' and 'photos')\n",
        "# For 'features' column: Count the number of features in the list\n",
        "df_filtered['features_count'] = df_filtered['features'].apply(lambda x: len(eval(x)) if isinstance(x, str) else 0)\n",
        "\n",
        "# For 'photos' column: Count the number of photos in the list\n",
        "df_filtered['photos_count'] = df_filtered['photos'].apply(lambda x: len(eval(x)) if isinstance(x, str) else 0)\n",
        "\n",
        "# Drop original 'features' and 'photos' columns\n",
        "df_filtered.drop(columns=['features', 'photos'], inplace=True)\n",
        "\n",
        "# Step 5: Handle text columns like 'description' if present\n",
        "if 'description' in df_filtered.columns:\n",
        "    # Use CountVectorizer to convert descriptions to numerical values\n",
        "    vectorizer = CountVectorizer(stop_words='english', max_features=100)  # Limiting to top 100 features for simplicity\n",
        "    description_matrix = vectorizer.fit_transform(df_filtered['description'])\n",
        "    description_df = pd.DataFrame(description_matrix.toarray(), columns=vectorizer.get_feature_names_out())\n",
        "    df_filtered = pd.concat([df_filtered, description_df], axis=1)\n",
        "    df_filtered.drop(columns=['description'], inplace=True)"
      ],
      "metadata": {
        "id": "7v2EjjfBCooo"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: One-hot encode categorical columns\n",
        "categorical_columns = ['building_id', 'display_address', 'street_address']\n",
        "df_encoded = pd.get_dummies(df_filtered, columns=categorical_columns, drop_first=True)\n",
        "\n",
        "# Step 7: Label encode the target column (interest_level)\n",
        "label_encoder = LabelEncoder()\n",
        "df_encoded['interest_level'] = label_encoder.fit_transform(df_encoded['interest_level'])\n",
        "\n",
        "# Define the target column (ensure this matches your target column name)\n",
        "target_column = 'interest_level'\n",
        "\n",
        "# Step 8: Separate features (X) and target (y)\n",
        "X = df_encoded.drop(columns=[target_column])\n",
        "y = df_encoded[target_column]"
      ],
      "metadata": {
        "id": "kw9U6P5MCx_a"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 9: Train/Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=5)"
      ],
      "metadata": {
        "id": "IuzEP2VgC5G4"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 10: Train a decision tree classifier\n",
        "clf = DecisionTreeClassifier(max_depth=2, random_state=5)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Step 11: Evaluate the model\n",
        "y_pred = clf.predict(X_test)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "\n",
        "# Optional: Predict on new unseen data\n",
        "# Example:\n",
        "# new_data = pd.DataFrame([...])  # Your new data to predict on\n",
        "# new_data_encoded = pd.get_dummies(new_data, columns=categorical_columns, drop_first=True)\n",
        "# new_predictions = clf.predict(new_data_encoded)\n",
        "# new_predictions = label_encoder.inverse_transform(new_predictions)  # Convert to original labels"
      ],
      "metadata": {
        "id": "lJ0eDhPBD1HF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17f23e4f-5b79-41fa-9a80-62096d8b9e03"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8473439917483239\n"
          ]
        }
      ]
    }
  ]
}