{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import ast"
      ],
      "metadata": {
        "id": "KAgRSCl67NYL"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Load the dataset\n",
        "df_filtered = pd.read_csv('/content/balanced_data_with_sentiment 1.csv', on_bad_lines='skip')\n",
        "print(df_filtered.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eRaGGCBG0XG-",
        "outputId": "f6a1a725-880a-4efa-b8a3-a93fbb0af39d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 102750 entries, 0 to 102749\n",
            "Columns: 119 entries, bathrooms to quarter\n",
            "dtypes: float64(113), object(6)\n",
            "memory usage: 93.3+ MB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Convert 'created' column to datetime format\n",
        "df_filtered['created'] = pd.to_datetime(df_filtered['created'])\n",
        "\n",
        "# Step 3: Extract useful components from the 'created' column\n",
        "df_filtered['year'] = df_filtered['created'].dt.year\n",
        "df_filtered['month'] = df_filtered['created'].dt.month\n",
        "df_filtered['day'] = df_filtered['created'].dt.day\n",
        "df_filtered['hour'] = df_filtered['created'].dt.hour\n",
        "df_filtered['minute'] = df_filtered['created'].dt.minute\n",
        "df_filtered['second'] = df_filtered['created'].dt.second\n",
        "\n",
        "# Drop the original 'created' column as it's no longer needed\n",
        "df_filtered.drop(columns=['created', 'manager_id', 'date'], inplace=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "id": "TdS_I8Tm6RhE",
        "outputId": "3fb5263c-6d7d-427a-be0d-344d52a6e03d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "\"['manager_id'] not found in axis\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-9cbdc13b41ff>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Drop the original 'created' column as it's no longer needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mdf_filtered\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'created'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'manager_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   5579\u001b[0m                 \u001b[0mweight\u001b[0m  \u001b[0;36m1.0\u001b[0m     \u001b[0;36m0.8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5580\u001b[0m         \"\"\"\n\u001b[0;32m-> 5581\u001b[0;31m         return super().drop(\n\u001b[0m\u001b[1;32m   5582\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5583\u001b[0m             \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4786\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4787\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4788\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4790\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[1;32m   4828\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4829\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4830\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4831\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_axis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   7068\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7069\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7070\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{labels[mask].tolist()} not found in axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7071\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7072\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"['manager_id'] not found in axis\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Process list columns ('features' and 'photos')\n",
        "# Safely convert string representations of lists to actual lists\n",
        "df_filtered['features'] = df_filtered['features'].apply(\n",
        "    lambda x: ast.literal_eval(x) if isinstance(x, str) else x\n",
        ")\n",
        "df_filtered['photos'] = df_filtered['photos'].apply(\n",
        "    lambda x: ast.literal_eval(x) if isinstance(x, str) else x\n",
        ")\n",
        "\n",
        "# For 'features' column: Count the number of features in the list\n",
        "df_filtered['features_count'] = df_filtered['features'].apply(\n",
        "    lambda x: len(x) if isinstance(x, list) else 0\n",
        ")\n",
        "\n",
        "# For 'photos' column: Count the number of photos in the list\n",
        "df_filtered['photos_count'] = df_filtered['photos'].apply(\n",
        "    lambda x: len(x) if isinstance(x, list) else 0\n",
        ")\n",
        "\n",
        "# Print the counts to verify\n",
        "print(df_filtered[['features_count', 'photos_count']].head())\n",
        "\n",
        "# Drop original 'features' and 'photos' columns\n",
        "df_filtered.drop(columns=['features', 'photos'], inplace=True)"
      ],
      "metadata": {
        "id": "7v2EjjfBCooo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca1f096c-3d30-4f5b-88a6-194298e9e074"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   features_count  photos_count\n",
            "0               3             6\n",
            "1               6             7\n",
            "2               8             5\n",
            "3              12             7\n",
            "4               3             3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Handle text columns like 'description' if present\n",
        "if 'description' in df_filtered.columns:\n",
        "    df_filtered['description'] = df_filtered['description'].fillna(\"\")\n",
        "    vectorizer = CountVectorizer(stop_words='english', max_features=100)\n",
        "    description_matrix = vectorizer.fit_transform(df_filtered['description'])\n",
        "    description_df = pd.DataFrame(description_matrix.toarray(), columns=vectorizer.get_feature_names_out())\n",
        "    df_filtered = pd.concat([df_filtered, description_df], axis=1)\n",
        "    df_filtered.drop(columns=['description'], inplace=True)\n",
        "print(df_filtered.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rci2DHIz1v3J",
        "outputId": "7e237eab-4113-4c77-ca34-ff0463abdbaa"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   bathrooms  bedrooms                       building_id  \\\n",
            "0        1.0         3                                 0   \n",
            "1        2.0         4  1f31e9001330dad4c202f92dc8ab8724   \n",
            "2        1.0         1  5565db9b7cba3603834c4aa6f2950960   \n",
            "3        2.0         2  2787598123c55dbf45b514958909c79c   \n",
            "4        1.0         0  a06178cb6130c1cc3d7fde9d5cf6417f   \n",
            "\n",
            "             display_address  latitude  listing_id  longitude  price  \\\n",
            "0  W 43rd Street and 9th Ave   40.7591     7196004   -73.9922   3325   \n",
            "1                  E 66th St   40.7640     7099693   -73.9591   5500   \n",
            "2                   Broadway   40.8198     7012584   -73.9578   1995   \n",
            "3           West 42nd Street   40.7610     7173483   -73.9990   4600   \n",
            "4           East 89th Street   40.7794     7130142   -73.9498   1999   \n",
            "\n",
            "              street_address interest_level  ...  unit  view  viewing  views  \\\n",
            "0  W 43rd Street and 9th Ave           high  ...     0     0        0      0   \n",
            "1              354 E 66th St           high  ...     0     0        1      0   \n",
            "2              3333 Broadway         medium  ...     0     0        0      1   \n",
            "3       620 West 42nd Street            low  ...     1     0        0      1   \n",
            "4       306 East 89th Street         medium  ...     0     0        0      0   \n",
            "\n",
            "   walk  washer  website_redacted  west  windows  york  \n",
            "0     0       0                 0     0        0     0  \n",
            "1     0       0                 1     0        1     0  \n",
            "2     0       0                 1     0        1     1  \n",
            "3     2       1                 1     2        0     0  \n",
            "4     0       0                 1     0        0     1  \n",
            "\n",
            "[5 rows x 121 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: One-hot encode categorical columns\n",
        "categorical_columns = ['building_id', 'display_address', 'street_address']\n",
        "df_encoded = pd.get_dummies(df_filtered, columns=categorical_columns, drop_first=True)\n",
        "\n",
        "# Step 7: Label encode the target column (interest_level)\n",
        "label_encoder = LabelEncoder()\n",
        "df_encoded['interest_level'] = label_encoder.fit_transform(df_encoded['interest_level'])"
      ],
      "metadata": {
        "id": "kw9U6P5MCx_a"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the target column (ensure this matches your target column name)\n",
        "target_column = 'interest_level'\n",
        "# Step 8: Separate features (X) and target (y)\n",
        "X = df_encoded.drop(columns=[target_column])\n",
        "y = df_encoded[target_column]"
      ],
      "metadata": {
        "id": "6gh5YJoH9Odq"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 9: Train/Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=5)"
      ],
      "metadata": {
        "id": "IuzEP2VgC5G4"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 10: Train a decision tree classifier\n",
        "clf = DecisionTreeClassifier(max_depth=2, random_state=5)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Step 11: Evaluate the model\n",
        "y_pred = clf.predict(X_test)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "id": "lJ0eDhPBD1HF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a533f839-b2bc-4d17-bd3a-fe18ca121c70"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.4350851581508516\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Random Forest**"
      ],
      "metadata": {
        "id": "_1l_iPrWu2Xz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "TgZQlVflu1tW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = rf_model.predict(X_test)\n",
        "y_prob = rf_model.predict_proba(X_test)[:, 1]"
      ],
      "metadata": {
        "id": "82gC_ZANvSD6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Accuracy Score:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(cm, annot=True, fmt='d')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "laEKuywYvTqA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Manually select three sets of hyperparameters\n",
        "param_sets = [\n",
        "    {'n_estimators': 100, 'max_depth': None, 'min_samples_split': 2},\n",
        "    {'n_estimators': 200, 'max_depth': 20, 'min_samples_split': 5},\n",
        "    {'n_estimators': 300, 'max_depth': 30, 'min_samples_split': 10},\n",
        "]\n",
        "\n",
        "# Store results for comparison\n",
        "results = []\n",
        "\n",
        "for i, params in enumerate(param_sets):\n",
        "    print(f\"Training model {i + 1} with parameters: {params}\")\n",
        "    # Train Random Forest with the selected hyperparameters\n",
        "    rf_model = RandomForestClassifier(**params, random_state=42)\n",
        "    rf_model.fit(X_train, y_train)\n",
        "\n",
        "    # Evaluate on the test set\n",
        "    y_test_pred = rf_model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_test_pred)\n",
        "\n",
        "    # Store results\n",
        "    results.append({'params': params, 'accuracy': accuracy})\n",
        "\n",
        "    # Print accuracy and confusion matrix\n",
        "    print(f\"Model {i + 1} Accuracy: {accuracy:.4f}\")\n",
        "    print(\"Classification Report:\\n\", classification_report(y_test, y_test_pred))\n",
        "\n",
        "    # Plot confusion matrix\n",
        "    cm = confusion_matrix(y_test, y_test_pred)\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "    plt.title(f\"Confusion Matrix for Model {i + 1}\")\n",
        "    plt.xlabel(\"Predicted Label\")\n",
        "    plt.ylabel(\"True Label\")\n",
        "    plt.show()\n",
        "\n",
        "# Compare results\n",
        "print(\"\\nComparison of Results:\")\n",
        "for result in results:\n",
        "    print(f\"Parameters: {result['params']}, Accuracy: {result['accuracy']:.4f}\")"
      ],
      "metadata": {
        "id": "XCxop0SVvVHQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cross-validation**"
      ],
      "metadata": {
        "id": "g7TS_SOnvaAw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Define the first set of hyperparameters\n",
        "params = {'n_estimators': 100, 'max_depth': None, 'min_samples_split': 2}\n",
        "\n",
        "# Number of folds for cross-validation\n",
        "cv_folds = 5\n",
        "\n",
        "print(f\"Performing cross-validation with parameters: {params}\")\n",
        "# Initialize Random Forest with the selected hyperparameters\n",
        "rf_model = RandomForestClassifier(**params, random_state=42)\n",
        "\n",
        "# Perform cross-validation\n",
        "scores = cross_val_score(rf_model, X_train, y_train, cv=cv_folds, scoring='accuracy')\n",
        "\n",
        "# Calculate mean accuracy and standard deviation\n",
        "mean_score = scores.mean()\n",
        "std_dev = scores.std()\n",
        "\n",
        "# Print cross-validation results\n",
        "print(f\"Mean Accuracy: {mean_score:.4f}, Std Dev: {std_dev:.4f}\")"
      ],
      "metadata": {
        "id": "4EAd3IzavX8_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}